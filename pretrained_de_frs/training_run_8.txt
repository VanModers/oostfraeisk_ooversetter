2025-09-08 11:11:44.277883: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-09-08 11:11:44.296445: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1757329904.318438    1555 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1757329904.325093    1555 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1757329904.342347    1555 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1757329904.342374    1555 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1757329904.342378    1555 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1757329904.342380    1555 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-09-08 11:11:44.347247: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Downloading builder script: 4.20kB [00:00, 13.9MB/s]
tokenizer_config.json: 100% 42.0/42.0 [00:00<00:00, 386kB/s]
source.spm: 100% 829k/829k [00:00<00:00, 12.2MB/s]
target.spm: 100% 814k/814k [00:00<00:00, 99.3MB/s]
vocab.json: 1.33MB [00:00, 188MB/s]
config.json: 1.38kB [00:00, 8.14MB/s]
/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.
  warnings.warn("Recommended: pip install sacremoses.")
pytorch_model.bin: 100% 297M/297M [00:02<00:00, 99.0MB/s]
generation_config.json: 100% 293/293 [00:00<00:00, 3.58MB/s]
model.safetensors:   7% 21.0M/297M [00:02<00:26, 10.3MB/s]Loading dataset
Finished loading dataset
/content/oostfraeisk_ooversetter/pretrained_de_frs/trainer.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.
  trainer = Seq2SeqTrainer(
model.safetensors:  14% 41.9M/297M [00:02<00:11, 21.4MB/s]The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.
wandb: (1) Create a W&B account
wandb: (2) Use an existing W&B account
wandb: (3) Don't visualize my results
model.safetensors: 100% 297M/297M [00:05<00:00, 57.8MB/s]
3
wandb: You chose "Don't visualize my results"
wandb: Tracking run with wandb version 0.21.3
wandb: W&B syncing is set to `offline` in this directory. Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.
wandb: Run data is saved locally in /content/oostfraeisk_ooversetter/wandb/offline-run-20250908_111207-u5qvmhtw
{'loss': 0.1372, 'grad_norm': 0.1984369158744812, 'learning_rate': 4.894641273594866e-05, 'epoch': 0.15}
{'loss': 0.0571, 'grad_norm': 0.1743813306093216, 'learning_rate': 4.789071407457455e-05, 'epoch': 0.3}
{'loss': 0.047, 'grad_norm': 0.14885322749614716, 'learning_rate': 4.6835015413200455e-05, 'epoch': 0.44}
{'loss': 0.0436, 'grad_norm': 0.17164133489131927, 'learning_rate': 4.5779316751826364e-05, 'epoch': 0.59}
{'loss': 0.0397, 'grad_norm': 0.1420097053050995, 'learning_rate': 4.4723618090452266e-05, 'epoch': 0.74}
{'loss': 0.036, 'grad_norm': 0.13799428939819336, 'learning_rate': 4.366791942907816e-05, 'epoch': 0.89}
 14% 3382/23681 [30:32<3:02:10,  1.86it/s]
  0% 0/32 [00:00<?, ?it/s]
  6% 2/32 [00:01<00:17,  1.76it/s]
  9% 3/32 [00:02<00:24,  1.19it/s]
 12% 4/32 [00:03<00:26,  1.07it/s]
 16% 5/32 [00:04<00:25,  1.06it/s]
 19% 6/32 [00:05<00:25,  1.00it/s]
 22% 7/32 [00:06<00:23,  1.04it/s]
 25% 8/32 [00:07<00:22,  1.05it/s]
 28% 9/32 [00:08<00:25,  1.10s/it]
 31% 10/32 [00:10<00:27,  1.24s/it]
 34% 11/32 [00:11<00:24,  1.15s/it]
 38% 12/32 [00:12<00:21,  1.09s/it]
 41% 13/32 [00:13<00:23,  1.26s/it]
 44% 14/32 [00:15<00:24,  1.35s/it]
 47% 15/32 [00:16<00:21,  1.24s/it]
 50% 16/32 [00:17<00:18,  1.18s/it]
 53% 17/32 [00:18<00:17,  1.17s/it]
 56% 18/32 [00:19<00:16,  1.15s/it]
 59% 19/32 [00:20<00:13,  1.02s/it]
 62% 20/32 [00:21<00:13,  1.12s/it]
 66% 21/32 [00:22<00:11,  1.03s/it]
 69% 22/32 [00:24<00:13,  1.31s/it]
 72% 23/32 [00:25<00:11,  1.30s/it]
 75% 24/32 [00:27<00:10,  1.28s/it]
 78% 25/32 [00:28<00:08,  1.27s/it]
 81% 26/32 [00:29<00:07,  1.20s/it]
 84% 27/32 [00:30<00:05,  1.10s/it]
 88% 28/32 [00:31<00:04,  1.12s/it]
 91% 29/32 [00:32<00:03,  1.19s/it]
 94% 30/32 [00:34<00:02,  1.21s/it]
 97% 31/32 [00:35<00:01,  1.24s/it]
                                          
{'eval_loss': 0.029241912066936493, 'eval_accuracy': 0.3929080104120623, 'eval_runtime': 38.734, 'eval_samples_per_second': 25.817, 'eval_steps_per_second': 0.826, 'epoch': 1.0}
 14% 3383/23681 [31:11<3:02:10,  1.86it/s]
100% 32/32 [00:35<00:00,  1.05s/it]
{'loss': 0.0337, 'grad_norm': 0.1676618903875351, 'learning_rate': 4.261222076770407e-05, 'epoch': 1.03}
{'loss': 0.0295, 'grad_norm': 0.14849326014518738, 'learning_rate': 4.155652210632997e-05, 'epoch': 1.18}
{'loss': 0.0288, 'grad_norm': 0.12237267941236496, 'learning_rate': 4.0500823444955873e-05, 'epoch': 1.33}
{'loss': 0.0279, 'grad_norm': 0.13418228924274445, 'learning_rate': 3.9445124783581775e-05, 'epoch': 1.48}
{'loss': 0.027, 'grad_norm': 0.13064685463905334, 'learning_rate': 3.838942612220768e-05, 'epoch': 1.63}
{'loss': 0.0261, 'grad_norm': 0.14135609567165375, 'learning_rate': 3.7333727460833586e-05, 'epoch': 1.77}
{'loss': 0.0253, 'grad_norm': 0.11393417418003082, 'learning_rate': 3.627802879945949e-05, 'epoch': 1.92}
 29% 6765/23681 [1:01:42<2:31:52,  1.86it/s]
  0% 0/32 [00:00<?, ?it/s]
  6% 2/32 [00:01<00:18,  1.67it/s]
  9% 3/32 [00:02<00:24,  1.17it/s]
 12% 4/32 [00:03<00:26,  1.06it/s]
 16% 5/32 [00:04<00:25,  1.05it/s]
 19% 6/32 [00:05<00:26,  1.01s/it]
 22% 7/32 [00:06<00:24,  1.03it/s]
 25% 8/32 [00:07<00:23,  1.04it/s]
 28% 9/32 [00:08<00:25,  1.11s/it]
 31% 10/32 [00:10<00:27,  1.23s/it]
 34% 11/32 [00:11<00:24,  1.15s/it]
 38% 12/32 [00:12<00:22,  1.11s/it]
 41% 13/32 [00:13<00:23,  1.25s/it]
 44% 14/32 [00:15<00:24,  1.35s/it]
 47% 15/32 [00:16<00:21,  1.24s/it]
 50% 16/32 [00:17<00:18,  1.18s/it]
 53% 17/32 [00:18<00:17,  1.17s/it]
 56% 18/32 [00:19<00:16,  1.16s/it]
 59% 19/32 [00:20<00:13,  1.04s/it]
 62% 20/32 [00:21<00:13,  1.13s/it]
 66% 21/32 [00:22<00:11,  1.05s/it]
 69% 22/32 [00:24<00:13,  1.34s/it]
 72% 23/32 [00:26<00:11,  1.32s/it]
 75% 24/32 [00:27<00:10,  1.30s/it]
 78% 25/32 [00:28<00:09,  1.29s/it]
 81% 26/32 [00:29<00:07,  1.20s/it]
 84% 27/32 [00:30<00:05,  1.10s/it]
 88% 28/32 [00:31<00:04,  1.14s/it]
 91% 29/32 [00:33<00:03,  1.21s/it]
 94% 30/32 [00:34<00:02,  1.22s/it]
 97% 31/32 [00:35<00:01,  1.25s/it]
                                            
{'eval_loss': 0.02175263501703739, 'eval_accuracy': 0.454201660036344, 'eval_runtime': 38.5846, 'eval_samples_per_second': 25.917, 'eval_steps_per_second': 0.829, 'epoch': 2.0}
 29% 6766/23681 [1:02:21<2:31:51,  1.86it/s]
100% 32/32 [00:36<00:00,  1.06s/it]
{'loss': 0.0228, 'grad_norm': 0.12026815861463547, 'learning_rate': 3.522233013808538e-05, 'epoch': 2.07}
{'loss': 0.0213, 'grad_norm': 0.11570354551076889, 'learning_rate': 3.416663147671129e-05, 'epoch': 2.22}
{'loss': 0.0209, 'grad_norm': 0.12183527648448944, 'learning_rate': 3.3110932815337194e-05, 'epoch': 2.36}
{'loss': 0.0207, 'grad_norm': 0.1294500231742859, 'learning_rate': 3.2055234153963096e-05, 'epoch': 2.51}
{'loss': 0.0202, 'grad_norm': 0.10415198653936386, 'learning_rate': 3.0999535492589e-05, 'epoch': 2.66}
{'loss': 0.0199, 'grad_norm': 0.14377573132514954, 'learning_rate': 2.99438368312149e-05, 'epoch': 2.81}
{'loss': 0.0194, 'grad_norm': 0.11707203090190887, 'learning_rate': 2.88881381698408e-05, 'epoch': 2.96}
 43% 10148/23681 [1:33:03<2:02:37,  1.84it/s]
  0% 0/32 [00:00<?, ?it/s]
  6% 2/32 [00:01<00:17,  1.75it/s]
  9% 3/32 [00:02<00:24,  1.20it/s]
 12% 4/32 [00:03<00:26,  1.07it/s]
 16% 5/32 [00:04<00:25,  1.06it/s]
 19% 6/32 [00:05<00:25,  1.01it/s]
 22% 7/32 [00:06<00:23,  1.06it/s]
 25% 8/32 [00:07<00:22,  1.05it/s]
 28% 9/32 [00:08<00:25,  1.09s/it]
 31% 10/32 [00:10<00:27,  1.25s/it]
 34% 11/32 [00:11<00:24,  1.17s/it]
 38% 12/32 [00:12<00:22,  1.11s/it]
 41% 13/32 [00:13<00:23,  1.26s/it]
 44% 14/32 [00:15<00:24,  1.36s/it]
 47% 15/32 [00:16<00:21,  1.25s/it]
 50% 16/32 [00:17<00:18,  1.19s/it]
 53% 17/32 [00:18<00:17,  1.17s/it]
 56% 18/32 [00:19<00:16,  1.16s/it]
 59% 19/32 [00:20<00:13,  1.03s/it]
 62% 20/32 [00:21<00:13,  1.13s/it]
 66% 21/32 [00:22<00:11,  1.03s/it]
 69% 22/32 [00:24<00:13,  1.33s/it]
 72% 23/32 [00:26<00:11,  1.32s/it]
 75% 24/32 [00:27<00:10,  1.31s/it]
 78% 25/32 [00:28<00:09,  1.31s/it]
 81% 26/32 [00:29<00:07,  1.22s/it]
 84% 27/32 [00:30<00:05,  1.12s/it]
 88% 28/32 [00:31<00:04,  1.15s/it]
 91% 29/32 [00:33<00:03,  1.22s/it]
 94% 30/32 [00:34<00:02,  1.24s/it]
 97% 31/32 [00:35<00:01,  1.27s/it]
                                             
{'eval_loss': 0.018089698627591133, 'eval_accuracy': 0.4897598349786356, 'eval_runtime': 38.614, 'eval_samples_per_second': 25.897, 'eval_steps_per_second': 0.829, 'epoch': 3.0}
 43% 10149/23681 [1:33:41<2:02:37,  1.84it/s]
100% 32/32 [00:36<00:00,  1.08s/it]
{'loss': 0.0174, 'grad_norm': 0.1027316227555275, 'learning_rate': 2.7832439508466707e-05, 'epoch': 3.1}
{'loss': 0.0166, 'grad_norm': 0.10084358602762222, 'learning_rate': 2.677674084709261e-05, 'epoch': 3.25}
{'loss': 0.0163, 'grad_norm': 0.1328265517950058, 'learning_rate': 2.5721042185718507e-05, 'epoch': 3.4}
{'loss': 0.0168, 'grad_norm': 0.1106804832816124, 'learning_rate': 2.4665343524344413e-05, 'epoch': 3.55}
{'loss': 0.0161, 'grad_norm': 0.10628246515989304, 'learning_rate': 2.3609644862970315e-05, 'epoch': 3.69}
{'loss': 0.0161, 'grad_norm': 0.13641586899757385, 'learning_rate': 2.2553946201596217e-05, 'epoch': 3.84}
{'loss': 0.0156, 'grad_norm': 0.11282183229923248, 'learning_rate': 2.149824754022212e-05, 'epoch': 3.99}
 57% 13531/23681 [2:04:28<1:31:57,  1.84it/s]
  0% 0/32 [00:00<?, ?it/s]
  6% 2/32 [00:01<00:17,  1.74it/s]
  9% 3/32 [00:02<00:24,  1.20it/s]
 12% 4/32 [00:03<00:25,  1.09it/s]
 16% 5/32 [00:04<00:25,  1.08it/s]
 19% 6/32 [00:05<00:25,  1.00it/s]
 22% 7/32 [00:06<00:24,  1.04it/s]
 25% 8/32 [00:07<00:23,  1.04it/s]
 28% 9/32 [00:08<00:25,  1.10s/it]
 31% 10/32 [00:10<00:27,  1.26s/it]
 34% 11/32 [00:11<00:24,  1.19s/it]
 38% 12/32 [00:12<00:22,  1.13s/it]
 41% 13/32 [00:13<00:24,  1.27s/it]
 44% 14/32 [00:15<00:24,  1.37s/it]
 47% 15/32 [00:16<00:21,  1.26s/it]
 50% 16/32 [00:17<00:18,  1.17s/it]
 53% 17/32 [00:18<00:17,  1.19s/it]
 56% 18/32 [00:19<00:16,  1.18s/it]
 59% 19/32 [00:20<00:13,  1.05s/it]
 62% 20/32 [00:22<00:13,  1.16s/it]
 66% 21/32 [00:22<00:11,  1.05s/it]
 69% 22/32 [00:24<00:13,  1.34s/it]
 72% 23/32 [00:26<00:12,  1.33s/it]
 75% 24/32 [00:27<00:10,  1.31s/it]
 78% 25/32 [00:28<00:09,  1.31s/it]
 81% 26/32 [00:29<00:07,  1.22s/it]
 84% 27/32 [00:30<00:05,  1.12s/it]
 88% 28/32 [00:31<00:04,  1.16s/it]
 91% 29/32 [00:33<00:03,  1.21s/it]
 94% 30/32 [00:34<00:02,  1.23s/it]
 97% 31/32 [00:35<00:01,  1.27s/it]
                                             
{'eval_loss': 0.0159606896340847, 'eval_accuracy': 0.52345169687147, 'eval_runtime': 38.7271, 'eval_samples_per_second': 25.822, 'eval_steps_per_second': 0.826, 'epoch': 4.0}
 57% 13532/23681 [2:05:07<1:31:56,  1.84it/s]
100% 32/32 [00:36<00:00,  1.06s/it]
{'loss': 0.0141, 'grad_norm': 0.16148017346858978, 'learning_rate': 2.0442548878848024e-05, 'epoch': 4.14}
{'loss': 0.0136, 'grad_norm': 0.11361655592918396, 'learning_rate': 1.9386850217473926e-05, 'epoch': 4.29}
{'loss': 0.0138, 'grad_norm': 0.1017717495560646, 'learning_rate': 1.8331151556099828e-05, 'epoch': 4.43}
{'loss': 0.0135, 'grad_norm': 0.10554096847772598, 'learning_rate': 1.727545289472573e-05, 'epoch': 4.58}
{'loss': 0.0134, 'grad_norm': 0.12065926939249039, 'learning_rate': 1.6219754233351632e-05, 'epoch': 4.73}
{'loss': 0.0135, 'grad_norm': 0.12126675248146057, 'learning_rate': 1.5164055571977537e-05, 'epoch': 4.88}
 71% 16914/23681 [2:35:54<1:01:15,  1.84it/s]
  0% 0/32 [00:00<?, ?it/s]
  6% 2/32 [00:01<00:17,  1.75it/s]
  9% 3/32 [00:02<00:24,  1.19it/s]
 12% 4/32 [00:03<00:26,  1.07it/s]
 16% 5/32 [00:04<00:25,  1.06it/s]
 19% 6/32 [00:05<00:26,  1.01s/it]
 22% 7/32 [00:06<00:23,  1.05it/s]
 25% 8/32 [00:07<00:22,  1.05it/s]
 28% 9/32 [00:08<00:25,  1.10s/it]
 31% 10/32 [00:10<00:27,  1.24s/it]
 34% 11/32 [00:11<00:24,  1.17s/it]
 38% 12/32 [00:12<00:22,  1.11s/it]
 41% 13/32 [00:13<00:23,  1.26s/it]
 44% 14/32 [00:15<00:24,  1.37s/it]
 47% 15/32 [00:16<00:21,  1.27s/it]
 50% 16/32 [00:17<00:19,  1.19s/it]
 53% 17/32 [00:18<00:17,  1.20s/it]
 56% 18/32 [00:19<00:16,  1.18s/it]
 59% 19/32 [00:20<00:13,  1.05s/it]
 62% 20/32 [00:22<00:13,  1.16s/it]
 66% 21/32 [00:22<00:11,  1.06s/it]
 69% 22/32 [00:24<00:13,  1.35s/it]
 72% 23/32 [00:26<00:11,  1.33s/it]
 75% 24/32 [00:27<00:10,  1.30s/it]
 78% 25/32 [00:28<00:09,  1.31s/it]
 81% 26/32 [00:29<00:07,  1.22s/it]
 84% 27/32 [00:30<00:05,  1.13s/it]
 88% 28/32 [00:31<00:04,  1.16s/it]
 91% 29/32 [00:33<00:03,  1.20s/it]
 94% 30/32 [00:34<00:02,  1.22s/it]
 97% 31/32 [00:35<00:01,  1.26s/it]
                                             
{'eval_loss': 0.014416266232728958, 'eval_accuracy': 0.5384313147684299, 'eval_runtime': 38.7279, 'eval_samples_per_second': 25.821, 'eval_steps_per_second': 0.826, 'epoch': 5.0}
 71% 16915/23681 [2:36:33<1:01:15,  1.84it/s]
100% 32/32 [00:36<00:00,  1.06s/it]
{'loss': 0.013, 'grad_norm': 0.09330551326274872, 'learning_rate': 1.4108356910603437e-05, 'epoch': 5.03}
{'loss': 0.0117, 'grad_norm': 0.10759717971086502, 'learning_rate': 1.3052658249229341e-05, 'epoch': 5.17}
{'loss': 0.0119, 'grad_norm': 0.12036314606666565, 'learning_rate': 1.1996959587855243e-05, 'epoch': 5.32}
{'loss': 0.0119, 'grad_norm': 0.09771615266799927, 'learning_rate': 1.0941260926481147e-05, 'epoch': 5.47}
{'loss': 0.0116, 'grad_norm': 0.1011280044913292, 'learning_rate': 9.885562265107049e-06, 'epoch': 5.62}
{'loss': 0.0119, 'grad_norm': 0.10913365334272385, 'learning_rate': 8.82986360373295e-06, 'epoch': 5.76}
{'loss': 0.0113, 'grad_norm': 0.09445986896753311, 'learning_rate': 7.774164942358854e-06, 'epoch': 5.91}
 86% 20297/23681 [3:07:21<30:39,  1.84it/s]
  0% 0/32 [00:00<?, ?it/s]
  6% 2/32 [00:01<00:17,  1.75it/s]
  9% 3/32 [00:02<00:24,  1.18it/s]
 12% 4/32 [00:03<00:25,  1.08it/s]
 16% 5/32 [00:04<00:25,  1.07it/s]
 19% 6/32 [00:05<00:25,  1.00it/s]
 22% 7/32 [00:06<00:23,  1.05it/s]
 25% 8/32 [00:07<00:22,  1.05it/s]
 28% 9/32 [00:08<00:25,  1.10s/it]
 31% 10/32 [00:10<00:27,  1.27s/it]
 34% 11/32 [00:11<00:24,  1.18s/it]
 38% 12/32 [00:12<00:22,  1.12s/it]
 41% 13/32 [00:13<00:24,  1.27s/it]
 44% 14/32 [00:15<00:24,  1.38s/it]
 47% 15/32 [00:16<00:21,  1.27s/it]
 50% 16/32 [00:17<00:19,  1.20s/it]
 53% 17/32 [00:18<00:17,  1.19s/it]
 56% 18/32 [00:19<00:16,  1.18s/it]
 59% 19/32 [00:20<00:13,  1.05s/it]
 62% 20/32 [00:22<00:13,  1.15s/it]
 66% 21/32 [00:22<00:11,  1.05s/it]
 69% 22/32 [00:24<00:13,  1.34s/it]
 72% 23/32 [00:26<00:11,  1.32s/it]
 75% 24/32 [00:27<00:10,  1.31s/it]
 78% 25/32 [00:28<00:09,  1.31s/it]
 81% 26/32 [00:29<00:07,  1.21s/it]
 84% 27/32 [00:30<00:05,  1.13s/it]
 88% 28/32 [00:31<00:04,  1.16s/it]
 91% 29/32 [00:33<00:03,  1.21s/it]
 94% 30/32 [00:34<00:02,  1.24s/it]
 97% 31/32 [00:35<00:01,  1.27s/it]
                                           
{'eval_loss': 0.013611670583486557, 'eval_accuracy': 0.5705024311183144, 'eval_runtime': 38.7736, 'eval_samples_per_second': 25.791, 'eval_steps_per_second': 0.825, 'epoch': 6.0}
 86% 20298/23681 [3:07:59<30:39,  1.84it/s]
100% 32/32 [00:36<00:00,  1.07s/it]
{'loss': 0.011, 'grad_norm': 0.0996050238609314, 'learning_rate': 6.718466280984756e-06, 'epoch': 6.06}
{'loss': 0.0106, 'grad_norm': 0.11337944120168686, 'learning_rate': 5.662767619610659e-06, 'epoch': 6.21}
{'loss': 0.0105, 'grad_norm': 0.13980542123317719, 'learning_rate': 4.607068958236562e-06, 'epoch': 6.36}
{'loss': 0.0105, 'grad_norm': 0.11236382275819778, 'learning_rate': 3.5513702968624636e-06, 'epoch': 6.5}
{'loss': 0.0107, 'grad_norm': 0.10667415708303452, 'learning_rate': 2.4956716354883664e-06, 'epoch': 6.65}
{'loss': 0.0105, 'grad_norm': 0.12146554887294769, 'learning_rate': 1.439972974114269e-06, 'epoch': 6.8}
{'loss': 0.0104, 'grad_norm': 0.10059645026922226, 'learning_rate': 3.842743127401715e-07, 'epoch': 6.95}
100% 23680/23681 [3:38:48<00:00,  1.84it/s]
  0% 0/32 [00:00<?, ?it/s]
  6% 2/32 [00:01<00:17,  1.75it/s]
  9% 3/32 [00:02<00:24,  1.20it/s]
 12% 4/32 [00:03<00:25,  1.09it/s]
 16% 5/32 [00:04<00:25,  1.07it/s]
 19% 6/32 [00:05<00:25,  1.01it/s]
 22% 7/32 [00:06<00:23,  1.06it/s]
 25% 8/32 [00:07<00:22,  1.05it/s]
 28% 9/32 [00:08<00:25,  1.10s/it]
 31% 10/32 [00:10<00:27,  1.26s/it]
 34% 11/32 [00:11<00:24,  1.17s/it]
 38% 12/32 [00:12<00:22,  1.12s/it]
 41% 13/32 [00:13<00:24,  1.27s/it]
 44% 14/32 [00:15<00:24,  1.38s/it]
 47% 15/32 [00:16<00:21,  1.27s/it]
 50% 16/32 [00:17<00:19,  1.19s/it]
 53% 17/32 [00:18<00:17,  1.19s/it]
 56% 18/32 [00:19<00:16,  1.19s/it]
 59% 19/32 [00:20<00:13,  1.06s/it]
 62% 20/32 [00:22<00:13,  1.17s/it]
 66% 21/32 [00:23<00:11,  1.08s/it]
 69% 22/32 [00:25<00:13,  1.37s/it]
 72% 23/32 [00:26<00:12,  1.34s/it]
 75% 24/32 [00:27<00:10,  1.32s/it]
 78% 25/32 [00:28<00:09,  1.32s/it]
 81% 26/32 [00:29<00:07,  1.24s/it]
 84% 27/32 [00:30<00:05,  1.15s/it]
 88% 28/32 [00:32<00:04,  1.17s/it]
 91% 29/32 [00:33<00:03,  1.21s/it]
 94% 30/32 [00:34<00:02,  1.21s/it]
 97% 31/32 [00:36<00:01,  1.26s/it]
                                           
{'eval_loss': 0.013242335990071297, 'eval_accuracy': 0.5770836402927164, 'eval_runtime': 38.8637, 'eval_samples_per_second': 25.731, 'eval_steps_per_second': 0.823, 'epoch': 7.0}
100% 23681/23681 [3:39:27<00:00,  1.84it/s]
100% 32/32 [00:36<00:00,  1.06s/it]
{'train_runtime': 13175.7172, 'train_samples_per_second': 57.498, 'train_steps_per_second': 1.797, 'train_loss': 0.022425147011233645, 'epoch': 7.0}
100% 23681/23681 [3:39:27<00:00,  1.80it/s]
/usr/local/lib/python3.12/dist-packages/transformers/modeling_utils.py:4034: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[57566]]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.
  warnings.warn(
wandb: 
wandb: You can sync this run to the cloud by running:
wandb: wandb sync /content/oostfraeisk_ooversetter/wandb/offline-run-20250908_111207-u5qvmhtw
wandb: Find logs at: wandb/offline-run-20250908_111207-u5qvmhtw/logs